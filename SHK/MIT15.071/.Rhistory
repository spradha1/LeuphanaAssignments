df1
colnames(df1) <- c('countries', 'pops', 'capitals')
df1 = data.frame(c('India', 'Vietnam'), c(1000, 88), c('Del', 'Han'))
df1
colnames(df1) <- c('countries', 'pops', 'capitals')
df1
df2 = rbind(df, df1)
df2
getwd()
who = read.csv('who.csv')
who = read.csv('who.csv')
getwd()
setwd("/home/sanjiv/Documents/Leuphana/LeuphanaStuff/SHK/MIT15.071/lectures/")
stevens = read.csv('datasets/stevens.csv')
str(stevens)
library(caTools)
set.seed(3000)
split = sample.split(stevens$Reverse, SplitRatio = 0.7)
train_stevens = subset(stevens, split == TRUE)
test_stevens = subset(stevens, split == FALSE)
install.packages("rpart")
library(rpart)
install.packages("rpart.plot")
library(rpart.plot)
mod1 = rpart(Reverse ~ Circuit + Issue + Petitioner + Respondent + LowerCourt + Unconst, data=train_stevens, method="class")
mod1 = rpart(Reverse ~ Circuit + Issue + Petitioner + Respondent + LowerCourt + Unconst, data=train_stevens, method="class", minbucket=25)
prp(mod1)
table(stevens$Respondent)
pred1 = predict(mod1, newdata = test_stevens, type="class")
table(test_stevens$Reverse, pred1)
112/(112+58)
library(ROCR)
prediction = predict(mod1, newdata=test_stevens)
prediction
pred1_rocr = prediction(prediction[,2], newdata=test_stevens)
stevens$Term[1:5]
stevens[1:5, 2:3]
pred1_rocr = prediction(prediction[,2], newdata=test_stevens$Reverse)
pred1_rocr = predict(prediction[,2], newdata=test_stevens$Reverse)
prediction
pred1
pred1_prob = predict(mod1, newdata=test_stevens)
rm(prediction)
pred1_prob
pred1_rocr = prediction(pred1_prob[,2], test_stevens$Reverse)
perf1_rocr = performance(pred1_rocr, 'tpr', "fpr")
plot(perf1_rocr)
auc1 = performance(pred1_rocr, 'auc')@y.values
auc1
auc1 = performance(pred1_rocr, 'auc')@y.values[0]
auc1
auc1 = as.numeric(performance(pred1_rocr, 'auc')@y.values)
auc1
mod2 = rpart(Reverse ~ Circuit + Issue + Petitioner + Respondent + LowerCourt + Unconst, data=train_stevens, method="class", minbucket=5)
prp(mod2)
mod3 = rpart(Reverse ~ Circuit + Issue + Petitioner + Respondent + LowerCourt + Unconst, data=train_stevens, method="class", minbucket=100)
prp(mod3)
install.packages("randomForest")
install.packages("randomForest")
install.packages("randomForest")
library(randomForest)
mod4 = glm(Reverse ~ Circuit + Issue + Petitioner + Respondent + LowerCourt + Unconst, data=train_stevens, family=binomial())
pred4 = predict(mod1, newdata = test_stevens, type="response")
pred4 = predict(mod4, newdata = test_stevens, type="response")
pred4
rm(list = c(pred4, mod4))
rm(c(pred4,mod4))
rm(pred4)
rm(mod4)
mod4 = randomForest(Reverse ~ Circuit + Issue + Petitioner + Respondent + LowerCourt + Unconst, data=train_stevens, nodesize=25, ntree=200)
train_stevens$Reverse = as.factor(train_stevens$Reverse)
test_stevens$Reverse = as.factor(test_stevens$Reverse)
mod4 = randomForest(Reverse ~ Circuit + Issue + Petitioner + Respondent + LowerCourt + Unconst, data=train_stevens, nodesize=25, ntree=200)
pred4 = predict(mod4, newdata=test_stevens)
table(test_stevens$Reverse, pred4)
set.seed(3000)
mod4 = randomForest(Reverse ~ Circuit + Issue + Petitioner + Respondent + LowerCourt + Unconst, data=train_stevens, nodesize=25, ntree=200)
pred4 = predict(mod4, newdata=test_stevens)
table(test_stevens$Reverse, pred4)
(54+72)/(54+72+21+23)
install.packages(caret)
install.packages("caret")
install.packages("e1071")
library(caret)
library(e1071)
folds = trainControl(method="cv", number=10)
cps = expand.grid(.cp=seq(0.01, 0.5, 0.01))
train(Reverse ~ Circuit + Issue + Petitioner + Respondent + LowerCourt + Unconst, data=train_stevens, method="rpart", trControl=folds, tuneGrid=cps)
?trainControl
?expand.grid
mod5 = rpart(Reverse ~ Circuit + Issue + Petitioner + Respondent + LowerCourt + Unconst, data=train_stevens, method='class', cp=0.18)
pred5 = predict(mod5, newdata = test_stevens, type="class")
?rpart
table(test_stevens$Reverse, pred5)
prp(mod5)
rm(list=ls())
mod4 = randomForest(Reverse ~ Circuit + Issue + Petitioner + Respondent + LowerCourt + Unconst, data=train_stevens, nodesize=25, ntree=200)
library(caTools)
stevens = read.csv('datasets/stevens.csv')
split = sample.split(stevens$Reverse, SplitRatio = 0.75)
train_set = subset(stevens, split == TRUE)
cart = rpart(Reverse ~ Respondent + Unconst + Circuit + Issue, data=train_set, method="class", minbucket=25)
jpeg('plots/CART.jpeg')
prp(cart)
cart = rpart(Reverse ~ Respondent + Unconst + Circuit + Issue, data=train_set, method="class", minbucket=100)
prp(cart)
prp(cart)str(train_set)
str(train_set)
prp(cart)
cart
library(rpart)
cart = rpart(Reverse ~ Respondent + Unconst + Circuit + Issue, data=train_set, method="class", minbucket=100)
cart
prp(cart)
jpeg('plots/CART.jpeg')
prp(cart)
dev.off()
prp(cart)
jpeg('plots/CART.jpeg')
prp(cart)
dev.off()
cart = rpart(Reverse ~ Respondent + Unconst + Circuit + Issue, data=train_set, method="class", minbucket=20)
dev.off()
jpeg('plots/CART.jpeg')
prp(cart)
dev.off()
rm(list=ls())
setwd("~/Documents/Leuphana/LeuphanaStuff/SHK/MIT15.071")
claims = read.csv('datasets/ClaimsData.csv')
str(claims)
table(claims$bucket2009)/nrow(claims)
library(caTools)
set.seed(88)
split = sample.split(claims, SplitRatio = 0.6)
claims_tr = subset(claims, split==TRUE)
claims_ts = subset(claims, split == FALSE)
mean(claims_tr$age)
table(claims_tr$diabetes)
table(claims_tr$diabetes)/nrow(claims_tr)
summary(claims_tr)
penalty_matrix = matrix(c(0,1,2,3,4,2,0,1,2,3,4,2,0,1,2,6,4,2,0,1,8,6,4,2,0), byrow = TRUE, nrow=5)
as.matrix(table(claims_ts$bucket2009, claims_ts$bucket2008))*penalty_matrix
sum(as.matrix(table(claims_ts$bucket2009, claims_ts$bucket2008))*penalty_matrix) / nrow(claims_ts)
penalty_matrix
as.matrix(table(claims_ts$bucket2009, claims_ts$bucket2008))
summary(claims_ts$bucket2008)
table(claims_ts$bucket2008)
conf_mat = as.matrix(table(claims_ts$bucket2009, claims_ts$bucket2008))
conf_mat[1,:]
conf_mat[1,1]
conf_mat[1,:]
conf_mat[1]
conf_mat[1, 2]
length(conf_mat)
conf_mat[1:5]
sum(conf_mat)
sum(conf_mat[1:5])
conf_mat[1,]
conf_mat = as.matrix(table(claims_ts$bucket2009, max(claims_ts$bucket2008)))
max(claims_ts$bucket2008)
max(claims_tr$bucket2008)
table(claims_tr$bucket2008)
table(claims_ts$bucket2009)
134506/nrow(claims_ts)
table(claims_ts$bucket2009)*matrix(c(0, 2, 4, 6, 8), byrow = 5, nrow=1)
?matrix
table(claims_ts$bucket2009)*c(0, 2, 4, 6, 8)
sum(table(claims_ts$bucket2009)*c(0, 2, 4, 6, 8))/nrow(claims_ts)
as.matrix(table(claims_ts$bucket2009, seq(1, 1, 0)))
as.matrix(table(claims_ts$bucket2009, rep(c(1), each=nrow(claims_ts)) ) )
as.matrix(table(claims_ts$bucket2009, rep(c(1), each=nrow(claims_ts)) ) )*penalty_matrix
as.matrix(table(claims_ts$bucket2009, rep(c(1), each=nrow(claims_ts)) ) )*penalty_matrix[,1]
sum(as.matrix(table(claims_ts$bucket2009, rep(c(1), each=nrow(claims_ts)) ) )*penalty_matrix[,1])
sum(as.matrix(table(claims_ts$bucket2009, rep(c(1), each=nrow(claims_ts)) ) )*penalty_matrix[,1])/nrow(claims_ts)
library(rpart)
library(rpart.plot)
mod1 = rpart(bucket2009 ~ age + arthritis + alzheimers + cancer + copd + depression + diabetes + heart.failure + ihd + kidney + osteoporosis + stroke + bucket2008 + reimbursement2008 + data=claims_tr, method="class", cp=0.00005)
mod1 = rpart(bucket2009 ~ age + arthritis + alzheimers + cancer + copd + depression + diabetes + heart.failure + ihd + kidney + osteoporosis + stroke + bucket2008 + reimbursement2008, data=claims_tr, method="class", cp=0.00005)
prp(mod1)
prp(mod1)
preds1 = predict(mod1, newdata=claims_ts, type='class')
table(claims_ts$bucket2009, preds1)
(125167 + 17317 + 106 + 271) / nrow(claims_ts)
as.matrix(table(claims_ts$bucket2009, preds1))*penalty_matrix
sum(as.matrix(table(claims_ts$bucket2009, preds1))*penalty_matrix)/nrow(claims_ts)
as.matrix(table(claims_ts$bucket2009, claims_ts$bucket2008))*penalty_matrix
as.matrix(table(claims_ts$bucket2009, claims_ts$bucket2008))
(120343 + 11772 + 2966 + 1736 + 115)/nrow(claims_tr)
mod1 = rpart(bucket2009 ~ age + arthritis + alzheimers + cancer + copd + depression + diabetes + heart.failure + ihd + kidney + osteoporosis + stroke + bucket2008 + reimbursement2008, data=claims_tr, method="class", cp=0.00005, parms = list(loss=penalty_matrix))
?list
preds1 = predict(mod1, newdata=claims_ts, type='class')
table(claims_ts$bucket2009, preds1)
(101726 + 21591 + 4722 + 919)/nrow(claims_ts)
sum(as.matrix(table(claims_ts$bucket2009, preds1))*penalty_matrix)/nrow(claims_ts)
cor(claims)
poll = read.csv('datasets/PollingData.csv')
str(poll)
cor(poll)
poll_num = poll[c('PropR', 'Republican')]
str(poll_num)
cor(poll_num)
rm(poll_num)
rm(poll)
rm(list=ls())
boston = read.csv('datasets/boston.csv')
str(boston)
plot(boston$LON, boston$LAT)
plot(boston$LON, boston$LAT)
dev.off()
dev.off()
plot(boston$LON, boston$LAT)
plot(boston$LON[boston$CHAS==1], boston$LAT[boston$CHAS==1], color='blue')
plot(boston$LON[boston$CHAS==1], boston$LAT[boston$CHAS==1], col='blue', pch=19)
plot(boston$LON, boston$LAT)
plot(boston$LON[boston$CHAS==1], boston$LAT[boston$CHAS==1], col='blue', pch=19)
plot(boston$LON, boston$LAT)
points(boston$LON[boston$CHAS==1], boston$LAT[boston$CHAS==1], col='blue', pch=19)
?points
points(boston$LON[boston$TRACT==3531], boston$LAT[boston$TRACT==3531], col='brown', pch=19)
points(boston$LON[boston$NOX>=.55], boston$LAT[boston$NOX>=.55], col='magenta', pch=19)
plot(boston$LON, boston$LAT)
points(boston$LON[boston$MEDV>=21.2], boston$LAT[boston$MEDV>=21.2], col='magenta', pch=19)
warnings()
plot(boston$LON, boston$LAT)
mod1 = lm(MEDV ~ LAT + LON, data=boston)
summary(mod1)
plot(boston$LON, boston$MEDV)
plot(boston$LON, boston$LAT)
points(boston$LON[boston$MEDV>=21.2], boston$LAT[boston$MEDV>=21.2], col='red', pch=46)
plot(boston$LON, boston$LAT)
points(boston$LON[boston$MEDV>=21.2], boston$LAT[boston$MEDV>=21.2], col='red', pch=12)
mod1$fitted.values
points(boston$LON[mod1$fitted.values>=21.2], boston$LAT[mod1$fitted.values>=21.2], col='green', pch="$")
summary(boston$MEDV)
boxplot(boston$MEDV)
library(rpart)
library(rpart.plot)
mod2 = rpart(MEDV ~ LAT + LON, data=boston)
summary(mod2)
prp(mod2)
plot(boston$LON, boston$LAT)
points(boston$LON[mod1$fitted.values>=21.2], boston$LAT[mod1$fitted.values>=21.2], col='green', pch="$")
plot(boston$LON, boston$LAT)
points(boston$LON[boston$MEDV>=21.2], boston$LAT[boston$MEDV>=21.2], col='red', pch=12)
preds2 = predict(mod2)
points(boston$LON[preds2>=21.2], boston$LAT[preds2>=21.2], col='green', pch="$")
mod3 = rpart(MEDV ~ LAT + LON, data=boston, minbucket=50)
plot(mod3)
text(mod3)
plot(boston$LON, boston$LAT)
abline(v=-71.07)
abline(h=-42.21)
abline(h=42.21)
abline(h=42.17)
points(boston$LON[preds2>=21.2], boston$LAT[preds2>=21.2], col='green', pch="$")
library(caTools)
set.seed(123)
split = sample.split(boston$MEDV, SplitRatio = 0.7)
train_b = subset(boston, split==TRUE)
test_b = subset(boston, split==FALSE)
plot(boston$LON, boston$LAT)
points(boston$LON[preds2>=21.2], boston$LAT[preds2>=21.2], col='green', pch="$")
points(boston$LON[mod3$fitted.values>=21.2], boston$LAT[mod3$fitted.values>=21.2], col='green', pch="$")
plot(boston$LON, boston$LAT)
points(boston$LON[mod3$fitted.values>=21.2], boston$LAT[mod3$fitted.values>=21.2], col='green', pch="$")
mod3$fitted.values
mod4 = lm(MEDV ~ LAT + LON +)
colnames(boston)
mod4 = lm(MEDV ~ LAT + LON + CRIM + ZN + CHAS + NOX + RM + INDUS + AGE + DIS + RAD + TAX + PTRATIO), data=train_b)
mod4 = lm(MEDV ~ LAT + LON + CRIM + ZN + CHAS + NOX + RM + INDUS + AGE + DIS + RAD + TAX + PTRATIO, data=train_b)
summary(mod4)
preds4 = predict(mod4, newdata=test_b)
sse4 = sum((preds4 - test_b$MEDV)^2)
sse4
mod5 = rpart(MEDV ~ LAT + LON + CRIM + ZN + CHAS + NOX + RM + INDUS + AGE + DIS + RAD + TAX + PTRATIO, data=train_b)
prp(mod5)
preds5 = predict(mod5, newdata=test_b)
sse5 = sum((preds5 - test_b$MEDV)^2)
sse5
library(caret)
library(e1071)
tr.control = trainControl(method='cv', number=10)
cp.grid = expand.grid(.cp=(0:10)*0.001)
0:10 * 0.001
mod6 = train(MEDV ~ LAT + LON + CRIM + ZN + CHAS + NOX + RM + INDUS + AGE + DIS + RAD + TAX + PTRATIO, trControl=tr.control, tuneGrid=cp.grid)
mod6 = train(MEDV ~ LAT + LON + CRIM + ZN + CHAS + NOX + RM + INDUS + AGE + DIS + RAD + TAX + PTRATIO, data=train_b, method="rpart", trControl=tr.control, tuneGrid=cp.grid)
mod6
cp.grid = expand.grid(.cp=(0:10)*0.0005)
mod6 = train(MEDV ~ LAT + LON + CRIM + ZN + CHAS + NOX + RM + INDUS + AGE + DIS + RAD + TAX + PTRATIO, data=train_b, method="rpart", trControl=tr.control, tuneGrid=cp.grid)
mod6
mod6$finalModel
prp(mod6)
prp(mod6$finalModel)
preds6 = predict(mod6, newdata = test_b$MEDV)
preds6 = predict(mod6, newdata = test_b)
sse6 = sum((preds6 - test_b$MEDV)^2)
sse6
rm(list = ls())
census = read.csv('datasets/census.csv')
str(census)
library(caTools)
set.seed(2000)
split = sample.split(census$over50k, SplitRatio = 0.6)
tr = subset(census, split==TRUE)
ts=subset(census, split==FALSE)
log1 = glm(over50k ~ ., data=tr, family=binomial)
census = read.csv('datasets/census.csv', stringsAsFactors = TRUE)
str(census)
split = sample.split(census$over50k, SplitRatio = 0.6)
tr = subset(census, split==TRUE)
ts=subset(census, split==FALSE)
log1 = glm(over50k ~ ., data=tr, family=binomial)
summary(log1)
pred_log1 = predict(log1, newdata = ts)
pred_log1
pred_log1 = predict(log1, newdata = ts, type='response')
summary(pred_log1)
table(ts$over50k, pred_log1 >= 0.5)
(9003+1903)/(9003+1903+1175+710)
table(tr$over50k)
table(ts$over50k)
9713/(nrow(ts))
library(ROCR)
rocr_pred_log1 = prediction(pred_log1, ts$over50k)
perf_log1 = as.numeric(performance(rocr_pred_log1,'auc')@y.values)
perf_log1
auc = as.numeric(performance(rocr_pred_log1,'auc')@y.values)
auc
rm(perf_log1)
library(rpart)
library(rpart.plot)
cart1 = rpart(over50k ~ ., method="class")
cart1 = rpart(over50k ~ ., data=tr, method="class")
?rpart
prp(cart1)
pred_cart1 = predict(cart1, newdata = ts, type='class')
table(ts$over50k,pred_cart1)
(9238+1593)/(9238+1593+475+1485)
set.seed(1)
tr1 = census[sample(nrow(census), 2000)]
tr1 = census[sample(nrow(census), 2000),]
?sample
sample(10, 2)
sample(10, 2)
sample(10, 4)
sample(4, 4)
sample(4, 4)
sample(4, 4)
sample(4, 5)
set.seed(!)
set.seed(1)
library(randomForest)
rf1 = randomForest(over50k ~ ., data=tr1)
pred_rf1 = predict(rf1, newdata = ts)
summary(pred_rf1)
table(ts$over50k,pred_rf1)
(8949+1996)/(8949+1996+1082+764)
(9238+1593)/(9238+1593+475+1485)
(9003+1903)/(9003+1903+1175+710)
cps = data.frame(.cp=seq(0.002, 0.092, 0.01))
library(caret)
library(e1071)
folds=trainControl(method=cv, number=10)
folds=trainControl(method='cv', number=10)
cv1 = train(over50k ~ ., method="rpart", data=tr, trControl=folds, tuneGrid=cps)
summary(cp1)
summary(cv1)
cv1
library(caret)
library(e1071)
set.seed(2)
folds=trainControl(method=cv, number=10)
folds=trainControl(method='cv', number=10)
cps = data.frame(.cp=seq(0.002, 0.092, 0.01))
cv1 = train(over50k ~ ., method="rpart", data=tr, trControl=folds, tuneGrid=cps)
cv1
censusTestMM = as.data.frame(model.matrix(over50k~.+0, data=censusTest))
tsMM = as.data.frame(model.matrix(over50k~.+0, data=ts))
str(tsMM)
pred_cart1_tsMM = predict(cv1$finalModel, newdata = tsMM, type="class")
table(tsMM$over50k,pred_cart1_tsMM)
table(tsMM$over50k)
tsMM$over50k
tsMM = as.data.frame(model.matrix(~.+0, data=ts))
pred_cart1_tsMM = predict(cv1$finalModel, newdata = tsMM, type="class")
tsMM
str(tsMM)
pred_cart1_tsMM = predict(cv1$finalModel, newdata = tsMM, type="class")
table(tsMM$over50k,pred_cart1_tsMM)
(9175+1750)/nrow(tsMM)
prp(cv1$finalModel)
(9238+1593)/(9238+1593+475+1485)
rm(list = ls())
gerber = read.csv('datasets/gerber.csv')
str(gerber)
table(gerber$voting)
table(gerber$voting, gerber$hawthorne)
table(gerber$hawthorne)
summary(gerber)
tapply(gerber$voting, gerber$hawthorne, mean)
tapply(gerber$voting, gerber$civicduty, mean)
tapply(gerber$voting, gerber$neighbors, mean)
tapply(gerber$voting, gerber$self, mean)
log1 = rpart(voting ~ hawthorne + civicduty + neighbours + self, data=gerber, family=binomial)
log1 = rpart(voting ~ hawthorne + civicduty + neighbors + self, data=gerber, family=binomial)
log1 = rpart(voting ~ hawthorne + civicduty + neighbors + self, data=gerber)
log1 = glm(voting ~ hawthorne + civicduty + neighbors + self, data=gerber, fmaily=binomial)
log1
log1 = glm(voting ~ hawthorne + civicduty + neighbors + self, data=gerber, family=binomial)
summary(log1)
pred_log1 = predict(log1, type='response')
table(gerber$voting, pred_log1 >= 0.5)
table(gerber$voting, pred_log1 >= 0.3)
(134513+51966)/nrow(gerber)
table(gerber$voting, pred_log1 >= 0.5)
235388/nrow(gerber)
rocr_pred_log1 = prediction(pred_log1, gerber$voting)
perf_log1 = performance(rocr_pred_log1, 'auc')
as.numeric((perf_log1)@y.values)
plot(perf_log1)
plot(perf_log1,colorize==TRUE)
perf_log1 = performance(rocr_pred_log1, 'tpr', 'fpr')
plot(perf_log1)
lines(c(0,0), c(1,1), col='red')
lines(x=c(0,0), y=c(1,1), col='red')
plot(perf_log1)
regtree1 = rpart(voting ~ hawthorne + civicduty + neighbors + self, data=gerber)
prp(regtree1)
regtree2 = rpart(voting ~ hawthorne + civicduty + neighbors + self, data=gerber, cp=0.0)
prp(regtree2)
regtree3 = rpart(voting ~ sex + hawthorne + civicduty + neighbors + self, data=gerber, cp=0.0)
prp(regtree3)
regtree4 = rpart(voting ~ control, data=gerber, cp=0.0)
regtree5 = rpart(voting ~ control + sex, data=gerber, cp=0.0)
prp(regtree4)
prp(regtree4, digits=6)
0.34-0.296638
prp(regtree5, digits=6)
log1 = glm(voting ~ control + sex, data=gerber, family=binomial)
summary(log1)
possibilities = data.frame(sex=c(0,0,1,1),control=c(0,1,0,1))
possibilities
pred_log1 = predict(log1, newdata=possibilities,type='response')
pred_log1
pred_log1[1] - .290456
pred_log1[4] - .290456
log2 = glm(voting ~ control + sex + sex:control, data=gerber, family=binomial)
summary(log2)
pred_log2 = predict(log2, newdata=possibilities,type='response')
pred_log2
pred_log2[4] - 0.290456
rm(list = ls())
statedata = read.csv('datasets/statedata.csv')
data(state) statedata = data.frame(state.x77)
statedata = data.frame(state.x77)
str(statedata)
lin1 = lm(Life.Exp ~ ., data=statedata)
summary(lin1)
lin1_sse = lin1$residuals
lin1_sse
lin1_sse = sum(lin1$residuals^2)
lin1_sse
lin2 = lm(Life.Exp ~ Population + Murder + Frost + HS.Grad, data=statedata)
summary(lin2)
lin2_sse = sum(lin2$residuals^2)
lin2_sse
rtree1 = rpart(Life.Exp ~ ., data=gerber)
rtree1 = rpart(Life.Exp ~ ., data=statedata)
prp(rtree1)
pred_rtree1 = predict(rtree1)
sse_rtree1 = sum((statedata$Life.Exp - pred_rtree1)^2)
sse_rtree1
rtree1_sse = sse_rtree1
rm(sse_rtree1)
rtree1_sse
rtree1 = rpart(Life.Exp ~ ., data=statedata, minbucket=5)
pred_rtree1 = predict(rtree1)
rtree1_sse = sum((statedata$Life.Exp - pred_rtree1)^2)
rtree1_sse
prp(rtree1)
rtree2 = rpart(Life.Exp ~ Area, data=statedata, minbucket=1)
pred_rtree2 = predict(rtree2)
rtree2_sse = sum((statedata$Life.Exp - pred_rtree2)^2)
rtree2_sse
prp(rtree2)
set.seed(111)
cps = expand.grid(.cp=seq(0.01, 0.5, 0.01))
folds = trainControl(method="cv",number=10)
cv1 = train(Life.Exp ~ ., method=rpart, data=statedata, trControl=folds, tuneGrid=cps)
cv1 = train(Life.Exp ~ ., method="rpart", data=statedata, trControl=folds, tuneGrid=cps)
cv1
rtree3 = rpart(Life.Exp ~ ., data=statedata, cp=0.11)
prp(rtree2)
prp(rtree3)
pred_rtree3 = predict(rtree3)
rtree3_sse = sum((statedata$Life.Exp - pred_rtree3)^2)
rtree3_sse
rtree4 = rpart(Life.Exp ~ Area, data=statedata, cp=0.11)
prp(rtree4)
rtree4 = rpart(Life.Exp ~ Area, data=statedata)
prp(rtree4)
cv_rtree4 = train(Life.Exp ~ Area, method="rpart", data=statedata, trControl=folds, tuneGrid=cps)
cv_rtree4
rtree4 = rpart(Life.Exp ~ Area, data=statedata, cp=0.05)
prp(rtree4)
pred_rtree4 = predict(rtree4)
rtree4_sse = sum((statedata$Life.Exp - pred_rtree4)^2)
rtree4_sse
prp(rtree4)
sumary(lin1)
summary(lin1)
rm(list=ls())
